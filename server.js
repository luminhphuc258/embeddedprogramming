// server.js
// Node 18+
// npm i express multer openai cors
import express from "express";
import cors from "cors";
import multer from "multer";
import fs from "fs";
import path from "path";
import { fileURLToPath } from "url";
import OpenAI from "openai";

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

const app = express();
const port = process.env.PORT || 8080;

app.use(cors());
app.use(express.json());

// Serve file mp3 c√¥ng khai
const publicDir = path.join(__dirname, "public");
const audioDir = path.join(publicDir, "audio");
fs.mkdirSync(audioDir, { recursive: true });
app.use("/audio", express.static(audioDir));

// Multer nh·∫≠n file t·ª´ ESP32 (multipart/form-data, field name: "audio")
const storage = multer.diskStorage({
  destination: (_, __, cb) => cb(null, path.join(__dirname, "uploads")),
  filename: (_, file, cb) => cb(null, Date.now() + "_" + (file.originalname || "audio.bin")),
});
fs.mkdirSync(path.join(__dirname, "uploads"), { recursive: true });
const upload = multer({ storage });

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

// === API ch√≠nh: ESP32 POST file -> tr·∫£ v·ªÅ mp3 url ===
app.post("/ask", upload.single("audio"), async (req, res) => {
  try {
    if (!req.file) return res.status(400).json({ success: false, error: "No file" });

    const filePath = req.file.path; // ƒë∆∞·ªùng d·∫´n file ESP32 upload (wav/pcm)

    // 1) STT (Speech-to-Text)
    // B·∫°n c√≥ th·ªÉ d√πng 'gpt-4o-transcribe' (n·∫øu enable) ho·∫∑c 'whisper-1'
    const stt = await openai.audio.transcriptions.create({
      file: fs.createReadStream(filePath),
      model: "gpt-4o-transcribe",  // n·∫øu t√†i kho·∫£n b·∫°n ch∆∞a c√≥, t·∫°m d√πng "whisper-1"
      // language: "vi"  // c√≥ th·ªÉ ch·ªâ ƒë·ªãnh
    });

    const userText = stt.text?.trim() || "";
    console.log("[STT] =>", userText);

    // 2) LLM: sinh c√¢u tr·∫£ l·ªùi (ng·∫Øn, th√¢n thi·ªán)
    const prompt = `Ng∆∞·ªùi d√πng h·ªèi (ti·∫øng Vi·ªát): "${userText}"
Tr·∫£ l·ªùi ng·∫Øn g·ªçn (1-2 c√¢u), th√¢n thi·ªán.`;

    const chat = await openai.chat.completions.create({
      model: "gpt-4o-mini",
      messages: [
        { role: "system", content: "B·∫°n l√† tr·ª£ l√Ω h·ªØu √≠ch, tr·∫£ l·ªùi ti·∫øng Vi·ªát t·ª± nhi√™n." },
        { role: "user", content: prompt }
      ],
      temperature: 0.6,
    });
    const answer = chat.choices?.[0]?.message?.content?.trim() || "Xin ch√†o!";

    // 3) TTS: t·∫°o MP3
    const mp3Name = `resp_${Date.now()}.mp3`;
    const mp3Path = path.join(audioDir, mp3Name);

    const speech = await openai.audio.speech.create({
      model: "gpt-4o-mini-tts",
      voice: "alloy",
      format: "mp3",
      input: answer,
    });

    const buf = Buffer.from(await speech.arrayBuffer());
    fs.writeFileSync(mp3Path, buf);

    // 4) Tr·∫£ v·ªÅ link HTTPS ƒë·∫øn MP3 (Railway s·∫Ω l√† https://<app>.up.railway.app)
    const host = process.env.PUBLIC_BASE_URL || `https://${req.headers.host}`;
    const url = `${host}/audio/${mp3Name}`;

    // (T√πy ch·ªçn) d·ªçn file upload g·ªëc
    try { fs.unlinkSync(filePath); } catch { }

    res.json({ success: true, text: answer, audio_url: url, format: "mp3" });
  } catch (err) {
    console.error(err);
    res.status(500).json({ success: false, error: String(err?.message || err) });
  }
});

app.get("/", (_, res) => res.type("text/plain").send("OK. POST /ask (multipart: audio=<file>)"));
app.listen(port, () => console.log(`üöÄ Server running on port ${port}`));
