// =======================
// ESP32 Chatbot + KWS + Music + TTS Server (enhanced + iTunes fix)
// 1ï¸âƒ£ Send to Python API first for intent label
// 2ï¸âƒ£ If "music"/"nhac" â†’ use Whisper to extract song name â†’ search iTunes + save MP3
// 3ï¸âƒ£ Else â†’ OpenAI transcribe + chat + TTS
// =======================

import express from "express";
import fs from "fs";
import path from "path";
import multer from "multer";
import { fileURLToPath } from "url";
import fetch from "node-fetch";
import FormData from "form-data";
import OpenAI from "openai";
import dotenv from "dotenv";
import cors from "cors";
import * as mm from "music-metadata";
import ffmpeg from "fluent-ffmpeg";
import ffmpegPath from "ffmpeg-static";

dotenv.config();
ffmpeg.setFfmpegPath(ffmpegPath);

const __dirname = path.dirname(fileURLToPath(import.meta.url));
const app = express();
const PORT = process.env.PORT || 8080;

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });
const PYTHON_API = "https://mylocalpythonserver-mypythonserver.up.railway.app/predict";

app.use(cors());
app.use("/audio", express.static(path.join(__dirname, "public/audio")));

// ===== Multer setup =====
const uploadsDir = path.join(__dirname, "uploads");
const audioDir = path.join(__dirname, "public/audio");
fs.mkdirSync(uploadsDir, { recursive: true });
fs.mkdirSync(audioDir, { recursive: true });

const storage = multer.diskStorage({
  destination: (_, __, cb) => cb(null, uploadsDir),
  filename: (_, file, cb) => cb(null, Date.now() + "_" + (file.originalname || "audio.wav")),
});
const upload = multer({ storage });

// ===== Helper functions =====
function detectLanguage(text) {
  const hasVi = /[ÄƒÃ¢Ä‘ÃªÃ´Æ¡Æ°Ã¡Ã áº£Ã£áº¡Ã©Ã¨áº»áº½áº¹Ã­Ã¬á»‰Ä©á»‹Ã³Ã²á»Ãµá»ÃºÃ¹á»§Å©á»¥Ã½á»³á»·á»¹á»µ]/i.test(text);
  const hasEn = /[a-zA-Z]/.test(text);
  if (hasVi && !hasEn) return "vi";
  if (hasEn && !hasVi) return "en";
  return "mixed";
}

// ===== Helper: Search iTunes and convert preview to MP3 =====
async function searchItunesAndSave(query) {
  try {
    console.log(`ğŸ¶ Searching iTunes for: ${query}`);
    const resp = await fetch(
      `https://itunes.apple.com/search?term=${encodeURIComponent(query)}&media=music&limit=1`
    );
    if (!resp.ok) throw new Error("iTunes search failed");
    const data = await resp.json();
    if (!data.results?.length) {
      console.warn("âš ï¸ No iTunes results found.");
      return null;
    }

    const song = data.results[0];
    const previewUrl = song.previewUrl;
    const trackName = song.trackName || "Unknown";
    const artistName = song.artistName || "Unknown Artist";

    const tmpM4A = path.join(audioDir, `song_${Date.now()}.m4a`);
    const outMP3 = tmpM4A.replace(".m4a", ".mp3");

    console.log(`â¬‡ï¸ Downloading preview: ${trackName} â€“ ${artistName}`);
    const songRes = await fetch(previewUrl);
    const arrayBuffer = await songRes.arrayBuffer();
    fs.writeFileSync(tmpM4A, Buffer.from(arrayBuffer));

    // Convert M4A â†’ MP3
    console.log("ğŸ§ Converting preview to MP3...");
    await new Promise((resolve, reject) =>
      ffmpeg(tmpM4A)
        .audioBitrate("128k")
        .toFormat("mp3")
        .on("end", resolve)
        .on("error", reject)
        .save(outMP3)
    );

    try {
      fs.unlinkSync(tmpM4A);
    } catch { }

    return {
      title: trackName,
      artist: artistName,
      filename: path.basename(outMP3),
    };
  } catch (err) {
    console.error("âŒ iTunes fetch/conversion error:", err.message);
    return null;
  }
}

// ===== MAIN HANDLER =====
app.post("/ask", upload.single("audio"), async (req, res) => {
  const cleanup = () => {
    try {
      if (req.file?.path) fs.unlinkSync(req.file.path);
    } catch { }
  };

  try {
    if (!req.file)
      return res.status(400).json({ success: false, error: "No audio file uploaded", audio_url: null });

    const wavPath = req.file.path;
    console.log(`ğŸ§ Received ${req.file.originalname} (${req.file.size} bytes)`);

    // === Step 1: send to Python API first ===
    console.log("ğŸ“¤ Sending to Python model for classification...");
    let label = "unknown";
    try {
      const form = new FormData();
      form.append("file", fs.createReadStream(wavPath));
      const r = await fetch(PYTHON_API, { method: "POST", body: form });
      const j = await r.json();
      label = j.label || "unknown";
    } catch (e) {
      console.warn("âš ï¸ Python API unreachable:", e.message);
    }
    console.log("ğŸ”¹ Label:", label);

    const host = process.env.PUBLIC_BASE_URL || `https://${req.headers.host}`;

    // === Step 2: Music branch ===
    if (label === "music" || label === "nhac") {
      console.log("ğŸµ Detected 'music' intent â†’ extracting song name...");

      let text = "";
      try {
        const tr = await openai.audio.transcriptions.create({
          file: fs.createReadStream(wavPath),
          model: "gpt-4o-mini-transcribe",
        });
        text = (tr.text || "").trim();
      } catch (e) {
        console.error("âš ï¸ Whisper error:", e.message);
      }

      let songName = "Vietnam top hits";
      try {
        const chat = await openai.chat.completions.create({
          model: "gpt-4o-mini",
          messages: [
            {
              role: "system",
              content:
                "Extract only the name of the song mentioned in the user's command. Respond with the song title only, no explanation.",
            },
            {
              role: "user",
              content: `Voice command: "${text}"`,
            },
          ],
        });
        songName = chat.choices?.[0]?.message?.content?.trim() || songName;
      } catch (e) {
        console.error("âš ï¸ Song name extraction error:", e.message);
      }

      console.log("ğŸ¯ Detected song name:", songName);

      try {
        const song = await searchItunesAndSave(songName);
        if (!song) {
          cleanup();
          return res.json({ success: false, type: "music", error: "No song found", audio_url: null });
        }

        cleanup();
        return res.json({
          success: true,
          type: "music",
          label,
          query: songName,
          text: `Playing: ${song.title} â€“ ${song.artist}`,
          audio_url: `${host}/audio/${song.filename}`,
          format: "mp3",
        });
      } catch (err) {
        console.error("âŒ Music branch error:", err.message);
        cleanup();
        return res.json({ success: false, type: "music", error: "Music failed", audio_url: null });
      }
    }

    // === Step 3: Chat branch ===
    console.log("ğŸ’¬ Transcribing and chatting...");

    let text = "";
    try {
      const tr = await openai.audio.transcriptions.create({
        file: fs.createReadStream(wavPath),
        model: "gpt-4o-mini-transcribe",
      });
      text = (tr.text || "").trim();
    } catch (e) {
      console.error("âš ï¸ STT error:", e.message);
    }
    console.log("ğŸ§  Text:", text);

    const lang = detectLanguage(text);
    const finalLang = lang === "mixed" ? "vi" : lang;

    let answer = finalLang === "vi" ? "Xin chÃ o!" : "Hello!";
    try {
      const chat = await openai.chat.completions.create({
        model: "gpt-4o-mini",
        messages: [
          {
            role: "system",
            content:
              finalLang === "vi"
                ? "Báº¡n lÃ  má»™t cÃ´ gÃ¡i tráº», thÃ¢n thiá»‡n, nÃ³i tá»± nhiÃªn báº±ng tiáº¿ng Viá»‡t."
                : "You are a friendly young woman who speaks natural English.",
          },
          {
            role: "user",
            content:
              finalLang === "vi"
                ? `NgÆ°á»i dÃ¹ng nÃ³i: "${text}". Tráº£ lá»i thÃ¢n thiá»‡n, ngáº¯n gá»n báº±ng tiáº¿ng Viá»‡t.`
                : `User said: "${text}". Reply briefly in friendly English.`,
          },
        ],
      });
      answer = chat.choices?.[0]?.message?.content?.trim() || answer;
    } catch (e) {
      console.error("âš ï¸ Chat error:", e.message);
    }

    const filename = `response_${Date.now()}.mp3`;
    const outPath = path.join(audioDir, filename);
    try {
      const speech = await openai.audio.speech.create({
        model: "gpt-4o-mini-tts",
        voice: finalLang === "vi" ? "nova" : "verse",
        format: "mp3",
        input: answer,
      });
      const buf = Buffer.from(await speech.arrayBuffer());
      fs.writeFileSync(outPath, buf);
    } catch (e) {
      console.error("âš ï¸ TTS error:", e.message);
    }

    cleanup();

    return res.json({
      success: true,
      type: "chat",
      label,
      text: answer,
      lang: finalLang,
      audio_url: `${host}/audio/${filename}`,
      format: "mp3",
    });
  } catch (err) {
    console.error("âŒ /ask error:", err);
    res.status(500).json({ success: false, error: err.message, audio_url: null });
  }
});

// ===== ROUTES =====
app.get("/", (req, res) =>
  res.send("âœ… ESP32 Chatbot + Python Classifier + Music + TTS server is running!")
);

app.listen(PORT, () => console.log(`ğŸš€ Server running on port ${PORT}`));
