// server.js
// Node 18+ / 20+
// npm i express multer openai cors node-fetch p-queue

import express from "express";
import cors from "cors";
import multer from "multer";
import fs from "fs";
import path from "path";
import fetch from "node-fetch";
import { fileURLToPath } from "url";
import OpenAI from "openai";
import PQueue from "p-queue"; // giá»›i háº¡n request song song

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

const app = express();
const port = process.env.PORT || 8080;

app.use(cors());
app.use(express.json({ limit: "10mb" }));

// ==== Folders ====
const publicDir = path.join(__dirname, "public");
const audioDir = path.join(publicDir, "audio");
fs.mkdirSync(audioDir, { recursive: true });
app.use("/audio", express.static(audioDir));

const uploadsDir = path.join(__dirname, "uploads");
fs.mkdirSync(uploadsDir, { recursive: true });

// ==== Multer upload ====
const storage = multer.diskStorage({
  destination: (_, __, cb) => cb(null, uploadsDir),
  filename: (_, file, cb) =>
    cb(null, Date.now() + "_" + (file.originalname || "audio.wav")),
});
const upload = multer({ storage });

// ==== OpenAI ====
const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

// ==== Queue (giá»›i háº¡n xá»­ lÃ½ Ä‘á»“ng thá»i Ä‘á»ƒ trÃ¡nh lá»—i body used already) ====
const queue = new PQueue({ concurrency: 2 });

// === Utility: phÃ¡t hiá»‡n ngÃ´n ngá»¯ ===
function detectLanguage(text) {
  const hasVietnamese =
    /[ÄƒÃ¢Ä‘ÃªÃ´Æ¡Æ°Ã¡Ã áº£Ã£áº¡Ã©Ã¨áº»áº½áº¹Ã­Ã¬á»‰Ä©á»‹Ã³Ã²á»Ãµá»ÃºÃ¹á»§Å©á»¥Ã½á»³á»·á»¹á»µ]/i.test(text);
  const hasEnglish = /[a-zA-Z]/.test(text);
  if (hasVietnamese && !hasEnglish) return "vi";
  if (hasEnglish && !hasVietnamese) return "en";
  return "mixed";
}

// === Helper: táº¡o file TTS an toÃ n ===
async function createSpeechFile({ text, voice, lang }) {
  const speechResp = await openai.audio.speech.create({
    model: "gpt-4o-mini-tts",
    voice: voice || (lang === "vi" ? "alloy" : "verse"),
    input: text,
    format: "mp3",
  });
  const buffer = Buffer.from(await speechResp.clone().arrayBuffer()); // clone trÃ¡nh body reuse
  const filePath = path.join(audioDir, `tts_${Date.now()}.mp3`);
  fs.writeFileSync(filePath, buffer);
  return filePath;
}

// === Main handler ===
async function handleAsk(req, res) {
  // Quan trá»ng: return Promise Ä‘á»ƒ Express chá» káº¿t quáº£
  return queue.add(async () => {
    try {
      if (!req.file) {
        return res
          .status(400)
          .json({ success: false, error: "No audio file uploaded" });
      }

      const filePath = req.file.path;
      console.log(`[ASK] file=${req.file.originalname} size=${req.file.size}`);

      // 1ï¸âƒ£ Speech-to-text
      const stt = await openai.audio.transcriptions.create({
        file: fs.createReadStream(filePath),
        model: "whisper-1",
      });
      const userText = stt.text?.trim() || "";
      console.log("[STT] =>", userText);

      // 2ï¸âƒ£ Detect language
      const lang = detectLanguage(userText);
      const finalLang = lang === "mixed" ? "vi" : lang;
      console.log(`[LANG DETECTED] ${lang} -> using ${finalLang}`);

      // 3ï¸âƒ£ Handle music requests ðŸŽµ
      const lower = userText.toLowerCase();
      if (
        lower.includes("phÃ¡t nháº¡c") ||
        lower.includes("má»Ÿ nháº¡c") ||
        lower.includes("báº­t nháº¡c") ||
        lower.includes("play music") ||
        lower.includes("play song")
      ) {
        const songQuery = userText
          .replace(/(phÃ¡t nháº¡c|má»Ÿ nháº¡c|báº­t nháº¡c|play music|play song)/gi, "")
          .trim();
        const q = songQuery || "relaxing background music";

        console.log("[MUSIC] Request:", q);

        // ThÃ´ng bÃ¡o báº±ng giá»ng nÃ³i
        const notice =
          finalLang === "vi" ? `Äang phÃ¡t bÃ i ${q}.` : `Playing the song ${q}.`;
        const noticePath = await createSpeechFile({
          text: notice,
          lang: finalLang,
        });

        // ðŸ”Ž TÃ¬m bÃ i hÃ¡t tháº­t qua iTunes Search API
        const searchUrl = `https://itunes.apple.com/search?term=${encodeURIComponent(
          q
        )}&media=music&limit=1`;
        let musicUrl = null;
        try {
          const resp = await fetch(searchUrl);
          const data = await resp.json();
          if (data.results && data.results.length > 0) {
            musicUrl = data.results[0].previewUrl; // 30s MP3 link
          }
        } catch (err) {
          console.error("iTunes fetch error:", err);
        }

        const host = process.env.PUBLIC_BASE_URL || `http://${req.headers.host}`;
        if (!musicUrl) musicUrl = `${host}/audio/${path.basename(noticePath)}`;

        console.log("[RESPONSE SENT] => music request");
        return res.json({
          success: true,
          text: notice,
          audio_url: `${host}/audio/${path.basename(noticePath)}`,
          music_url: musicUrl,
          type: "music",
        });
      }

      // 4ï¸âƒ£ Chat reply
      const systemPrompt =
        finalLang === "vi"
          ? "Báº¡n lÃ  má»™t cÃ´ gÃ¡i tráº», thÃ¢n thiá»‡n, nÃ³i tiáº¿ng Viá»‡t tá»± nhiÃªn."
          : "You are a friendly young woman assistant speaking natural English.";

      const prompt =
        finalLang === "vi"
          ? `NgÆ°á»i dÃ¹ng nÃ³i: "${userText}". Tráº£ lá»i ngáº¯n gá»n (1â€“2 cÃ¢u) báº±ng tiáº¿ng Viá»‡t, thÃ¢n thiá»‡n.`
          : `User said: "${userText}". Reply briefly (1â€“2 sentences) in friendly conversational English.`;

      const chat = await openai.chat.completions.create({
        model: "gpt-4o-mini",
        messages: [
          { role: "system", content: systemPrompt },
          { role: "user", content: prompt },
        ],
        temperature: 0.7,
      });
      const answer =
        chat.choices?.[0]?.message?.content?.trim() ||
        (finalLang === "vi" ? "Xin chÃ o!" : "Hello!");

      // 5ï¸âƒ£ Text-to-speech
      const mp3Path = await createSpeechFile({
        text: answer,
        lang: finalLang,
      });

      const host = process.env.PUBLIC_BASE_URL || `http://${req.headers.host}`;
      const url = `${host}/audio/${path.basename(mp3Path)}`;

      try {
        fs.unlinkSync(filePath);
      } catch { }

      console.log("[RESPONSE SENT] => chat reply");
      return res.json({
        success: true,
        text: answer,
        audio_url: url,
        lang: finalLang,
        format: "mp3",
      });
    } catch (err) {
      console.error("[ASK ERROR]", err);
      res.status(500).json({ success: false, error: err.message });
    }
  });
}

// === Routes ===
app.post("/ask", upload.single("audio"), handleAsk);
app.post("/api/ask", upload.single("audio"), handleAsk);

app.get("/", (_, res) =>
  res.send("âœ… OK. Use POST /ask (multipart: audio=<file>)")
);

app.listen(port, () => console.log(`ðŸš€ Server running on port ${port}`));
