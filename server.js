// server.js
// Node 18+  (package.json: { "type": "module" })
// npm i express multer openai cors

import express from "express";
import cors from "cors";
import multer from "multer";
import fs from "fs";
import path from "path";
import { fileURLToPath } from "url";
import OpenAI from "openai";

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

const app = express();
const port = process.env.PORT || 8080;

app.use(cors());
// Log má»i request Ä‘á»ƒ debug
app.use((req, _res, next) => {
  console.log(`[REQ] ${req.method} ${req.path}`);
  next();
});

// Báº­t JSON parser cho cÃ¡c route khÃ´ng dÃ¹ng multipart
app.use(express.json({ limit: "10mb" }));

// ==== ThÆ° má»¥c public Ä‘á»ƒ phÃ¡t file mp3 ====
const publicDir = path.join(__dirname, "public");
const audioDir = path.join(publicDir, "audio");
fs.mkdirSync(audioDir, { recursive: true });
app.use("/audio", express.static(audioDir));

// ==== Multer nháº­n file tá»« ESP32 (multipart/form-data, field name: "audio") ====
const uploadsDir = path.join(__dirname, "uploads");
fs.mkdirSync(uploadsDir, { recursive: true });
const storage = multer.diskStorage({
  destination: (_, __, cb) => cb(null, uploadsDir),
  filename: (_, file, cb) =>
    cb(null, Date.now() + "_" + (file.originalname || "audio.bin")),
});
const upload = multer({ storage });

// ==== OpenAI ====
const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

// ==== Utility: phÃ¡t hiá»‡n ngÃ´n ngá»¯ trong text ====
function detectLanguage(text) {
  const hasVietnamese =
    /[ÄƒÃ¢Ä‘ÃªÃ´Æ¡Æ°Ã¡Ã áº£Ã£áº¡Ã©Ã¨áº»áº½áº¹Ã­Ã¬á»‰Ä©á»‹Ã³Ã²á»Ãµá»ÃºÃ¹á»§Å©á»¥Ã½á»³á»·á»¹á»µ]/i.test(text);
  const hasEnglish = /[a-zA-Z]/.test(text);
  if (hasVietnamese && !hasEnglish) return "vi";
  if (hasEnglish && !hasVietnamese) return "en";
  return "mixed";
}

// ==== Handler chÃ­nh cho /ask vÃ  /api/ask ====
async function handleAsk(req, res) {
  try {
    if (!req.file) {
      return res
        .status(400)
        .json({ success: false, error: "No file (field name must be 'audio')" });
    }
    console.log(
      `[ASK] file=${req.file.originalname} size=${req.file.size} type=${req.file.mimetype}`
    );

    const filePath = req.file.path;

    // 1ï¸âƒ£ Speech-to-text
    const stt = await openai.audio.transcriptions.create({
      file: fs.createReadStream(filePath),
      model: process.env.STT_MODEL || "whisper-1",
    });

    const userText = stt.text?.trim() || "";
    console.log("[STT] =>", userText);

    // 2ï¸âƒ£ Nháº­n diá»‡n ngÃ´n ngá»¯
    const lang = detectLanguage(userText);
    const finalLang = lang === "mixed" ? "vi" : lang;
    console.log(`[LANG DETECTED] ${lang} â†’ using ${finalLang}`);

    // 3ï¸âƒ£ Táº¡o pháº£n há»“i báº±ng ChatGPT
    const prompt =
      finalLang === "vi"
        ? `NgÆ°á»i dÃ¹ng nÃ³i: "${userText}". Tráº£ lá»i thÃ¢n thiá»‡n, ngáº¯n gá»n (1â€“2 cÃ¢u) báº±ng tiáº¿ng Viá»‡t tá»± nhiÃªn.`
        : `User said: "${userText}". Reply briefly in friendly conversational English (1â€“2 sentences).`;

    const systemPrompt =
      finalLang === "vi"
        ? "Báº¡n lÃ  má»™t cÃ´ gÃ¡i tráº», nÃ³i giá»ng tá»± nhiÃªn, thÃ¢n thiá»‡n báº±ng tiáº¿ng Viá»‡t."
        : "You are a friendly young woman who speaks casual, natural English.";

    const chat = await openai.chat.completions.create({
      model: process.env.CHAT_MODEL || "gpt-4o-mini",
      messages: [
        { role: "system", content: systemPrompt },
        { role: "user", content: prompt },
      ],
      temperature: 0.8,
    });

    const answer =
      chat.choices?.[0]?.message?.content?.trim() ||
      (finalLang === "vi" ? "Xin chÃ o!" : "Hello there!");

    console.log("[AI REPLY] =>", answer);

    // 4ï¸âƒ£ TTS (Text-to-Speech)
    const mp3Name = `resp_${Date.now()}.mp3`;
    const mp3Path = path.join(audioDir, mp3Name);

    const speech = await openai.audio.speech.create({
      model: process.env.TTS_MODEL || "gpt-4o-mini-tts",
      voice: finalLang === "vi" ? "alloy" : "verse", // alloy = ná»¯ VN, verse = ná»¯ EN
      input: answer,
      format: "mp3",
    });

    const buf = Buffer.from(await speech.arrayBuffer());
    fs.writeFileSync(mp3Path, buf);

    const host = process.env.PUBLIC_BASE_URL || `http://${req.headers.host}`;
    const url = `${host}/audio/${mp3Name}`;

    // XÃ³a file táº¡m (upload)
    try {
      fs.unlinkSync(filePath);
    } catch { }

    console.log(`[RESPONSE SENT] => ${url}`);

    // 5ï¸âƒ£ Gá»­i káº¿t quáº£ JSON
    res.json({
      success: true,
      text: answer,
      lang: finalLang,
      audio_url: url,
      format: "mp3",
    });
  } catch (err) {
    console.error("[ASK ERROR]", err);
    res
      .status(500)
      .json({ success: false, error: String(err?.message || err) });
  }
}

// ==== Routes ====
app.post("/ask", upload.single("audio"), handleAsk);
app.post("/api/ask", upload.single("audio"), handleAsk);

app.get("/ask", (_req, res) =>
  res
    .status(405)
    .type("text/plain")
    .send("Use POST /ask (multipart: audio=<file>)")
);

app.get("/", (_req, res) =>
  res.type("text/plain").send("OK. POST /ask (multipart: audio=<file>)")
);

// 404 rÃµ rÃ ng
app.use((req, res) => {
  res
    .status(404)
    .json({ success: false, error: `Not found: ${req.method} ${req.path}` });
});

app.listen(port, () =>
  console.log(`ðŸš€ Server running on port ${port}`)
);
